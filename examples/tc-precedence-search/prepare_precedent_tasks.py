
"""Generate Harbor tasks for the SuperCon precedent search (dev set)."""

import argparse
import csv
import json
import shutil
from pathlib import Path

def repo_root() -> Path:
    return Path(__file__).resolve().parents[2]

def templates_dir() -> Path:
    return Path(__file__).parent / "search-template"

def pbench_eval_dir() -> Path:
    return repo_root() / "src/pbench_eval"

def read_template(relative_path: str) -> str:
    return (templates_dir() / relative_path).read_text()

def copy_template(relative_path: str, dest_path: Path) -> None:
    dest_path.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(templates_dir() / relative_path, dest_path)

def dockerfile_contents() -> str:
    return read_template("environment/Dockerfile")

def slugify(value: str) -> str:
    return (
        value.lower()
        .replace(" ", "-")
        .replace("/", "-")
        .replace("(", "")
        .replace(")", "")
    )

def build_task(task_dir: Path, row: dict[str, str], task_name: str) -> None:
    # 1. Setup dirs
    env_dir = task_dir / "environment"
    tests_dir = task_dir / "tests"
    solution_dir = task_dir / "solution"
    
    for d in [env_dir, tests_dir, solution_dir]:
        d.mkdir(parents=True, exist_ok=True)

    # 2. Extract values
    material = row["material"]
    is_sc = row["Has material been reported to be superconducting?"]  # "Yes" or "No"
    
    # Handle potentially empty/float values in CSV
    # The CSV was generated by pandas, so empty might be empty string or not present
    highest_tc = str(row.get("What is the highest measured Tc?", "") or "")
    lowest_tcn = str(row.get("What is the lowest temp for measurement at which material was not superconducting?", "") or "")

    # Cleanup values
    # Cleanup values: Ensure everything is N/A if missing
    if not highest_tc or highest_tc.lower() == "nan": 
        highest_tc = "N/A"
    if not lowest_tcn or lowest_tcn.lower() == "nan": 
        lowest_tcn = "N/A"

    # 3. Create Expected JSON (Ground Truth)
    # Mapping to the 3 output properties
    expected_rows = [
        {
            "material": material,
            "property_name": "is_superconducting",
            "property_value": is_sc,
            "rubric": "categorical"
        },
        {
            "material": material,
            "property_name": "highest_tc",
            "property_value": highest_tc,
            "rubric": "categorical" if highest_tc == "N/A" else "0.1% SI"
        },
        {
            "material": material,
            "property_name": "lowest_tcn",
            "property_value": lowest_tcn,
            "rubric": "categorical" if lowest_tcn == "N/A" else "0.1% SI"
        }
    ]
    
    expected = {
        "task": task_name,
        "refno": "precedent-search", # Placeholder
        "ground_truth": expected_rows,
    }
    (tests_dir / "expected.json").write_text(json.dumps(expected, indent=2))
    
    # 4. Instruction
    instruction_template = read_template("instruction.md.template")
    # Simple substitution
    instruction = instruction_template.replace("{material}", material)
    (task_dir / "instruction.md").write_text(instruction)
    
    # 5. Task TOML
    task_toml = read_template("task.toml.template").replace("{task_name}", task_name)
    (task_dir / "task.toml").write_text(task_toml)
    
    # 6. Dockerfile and Test Scripts
    (env_dir / "Dockerfile").write_text(dockerfile_contents())
    copy_template("tests/check_prediction.py", tests_dir / "check_prediction.py")
    copy_template("tests/test.sh", tests_dir / "test.sh")

    # Copy shared scoring utils
    shutil.copy2(pbench_eval_dir() / "utils.py", tests_dir / "pbench_eval_utils.py")
    
    # 7. Oracle Solution (solve.sh)
    # We construct a prediction matching the expected rows exactly
    prediction_rows = []
    for er in expected_rows:
        prediction_rows.append({
            "material": er["material"],
            "property_name": er["property_name"],
            "value_string": er["property_value"] 
        })
        
    solution_json = { "properties": prediction_rows }
    
    solution_script = f"""#!/bin/bash
set -euo pipefail

mkdir -p /app/output
cat > /app/output/predictions.json <<'EOF'
{json.dumps(solution_json, indent=2)}
EOF
"""
    (solution_dir / "solve.sh").write_text(solution_script)
    (solution_dir / "solve.sh").chmod(0o755)
    (tests_dir / "test.sh").chmod(0o755)


def write_job_config(tasks_dir: Path, job_path: Path) -> None:
    tasks_rel = (
        tasks_dir.relative_to(repo_root()) if tasks_dir.is_absolute() else tasks_dir
    )
    job_yaml = f"""\
jobs_dir: jobs
n_attempts: 1
timeout_multiplier: 1.0
orchestrator:
  type: local
  n_concurrent_trials: 2
  quiet: false
environment:
  type: docker
  force_build: true
  delete: true
agents:
  - name: oracle
datasets:
  - path: {tasks_rel.as_posix()}
"""
    job_path.parent.mkdir(parents=True, exist_ok=True)
    job_path.write_text(job_yaml)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--csv", type=Path, default=repo_root() / "examples/tc-precedence-search/SuperCon_Tc_Tcn_dev-set.csv")
    parser.add_argument("--output-dir", type=Path, default=repo_root() / "out/harbor/precedent-search")
    parser.add_argument("--limit", type=int, default=None)
    parser.add_argument("--write-job-config", action="store_true")
    parser.add_argument("--force", action="store_true")
    
    args = parser.parse_args()
    
    task_root = args.output_dir / "tc-precedence-search"
    tasks_dir = task_root / "tasks"
    
    if task_root.exists():
        if args.force:
            shutil.rmtree(task_root)
        elif any(task_root.iterdir()):
            print(f"Directory {task_root} exists. Use --force to overwrite.")
            return

    tasks_dir.mkdir(parents=True, exist_ok=True)

    print(f"Reading CSV: {args.csv}")
    with args.csv.open() as f:
        reader = csv.DictReader(f)
        rows = list(reader)
        
    if args.limit:
        rows = rows[:args.limit]
        
    print(f"Generating tasks for {len(rows)} materials...")
    
    for row in rows:
        material = row["material"]
        task_id = slugify(material)
        task_dir = tasks_dir / task_id
        task_dir.mkdir(parents=True, exist_ok=True)
        
        build_task(task_dir, row, "precedent-search")
        # print(f"Built task: {task_id}")
        
    print(f"All tasks built in {tasks_dir}")

    if args.write_job_config:
        job_path = task_root / "job.yaml"
        write_job_config(tasks_dir, job_path)
        print(f"Wrote job config -> {job_path}")

if __name__ == "__main__":
    main()
